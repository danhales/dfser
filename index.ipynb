{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conda environment (for when Dan forgets): speech-emotion\n",
    "\n",
    "Code from <a href=\"https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/\">here</a>.\n",
    "\n",
    "Goal is to deploy model in an Android app, so I'm making sure the code is actually reproducible here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index.ipynb                             \u001b[34mspeech-emotion-recognition-ravdess-data\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "#DataFlair - Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"speech-emotion-recognition-ravdess-data/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
    "\n",
    "#load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n",
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)\n",
    "\n",
    "y_train = pd.get_dummies(pd.DataFrame(y_train, columns=['label']), prefix='', prefix_sep='')\n",
    "y_test = pd.get_dummies(pd.DataFrame(y_test, columns=['label']), prefix='', prefix_sep='')\n",
    "\n",
    "#DataFlair - Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))\n",
    "#DataFlair - Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:17<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Initialize the Multi Layer Perceptron Classifier\n",
    "import tqdm\n",
    "tests = []\n",
    "for test in tqdm.trange(1, 100):\n",
    "    model=MLPClassifier(alpha=0.01,                # L2 penalty parameter (default 0.0001)          \n",
    "                        batch_size=256,            # size of minibatch (default: min(200, n_samples))\n",
    "                        epsilon=1e-08,             # value for numerical stability in adam\n",
    "                        hidden_layer_sizes=(300,), # sizes (number of neurons) in the hidden layers\n",
    "                        learning_rate='adaptive',  # fixed at learning_rate_init unless loss isn't decreasing, \n",
    "                        max_iter=500)              # maximum number of iterations to perform\n",
    "\n",
    "    #DataFlair - Train the model\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    #DataFlair - Predict for the test set\n",
    "    y_pred=model.predict(x_test)\n",
    "\n",
    "    #DataFlair - Calculate the accuracy of our model\n",
    "    accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "    #DataFlair - Print the accuracy\n",
    "    #print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "    tests.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.01,\n",
       " 'batch_size': 256,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (300,),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 500,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 coefficients in layer 0\n",
      "300 coefficients in layer 1\n"
     ]
    }
   ],
   "source": [
    "# the ith element in the list represents the weight metrix corresponding to layer i\n",
    "# \n",
    "for level, layer in enumerate(model.coefs_):\n",
    "    print(len(layer), 'coefficients in layer', level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 intercepts in layer 0\n",
      "4 intercepts in layer 1\n"
     ]
    }
   ],
   "source": [
    "for level, layer in enumerate(model.intercepts_):\n",
    "    print(len(layer), 'intercepts in layer', level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 300)               54300     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 55,504\n",
      "Trainable params: 55,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 20.5386 - accuracy: 0.2717 - val_loss: 10.2816 - val_accuracy: 0.3448\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3018 - accuracy: 0.2174 - val_loss: 8.1802 - val_accuracy: 0.2500\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2867 - accuracy: 0.3217 - val_loss: 12.3096 - val_accuracy: 0.2672\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.0746 - accuracy: 0.2674 - val_loss: 9.5311 - val_accuracy: 0.2672\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4547 - accuracy: 0.3087 - val_loss: 4.6208 - val_accuracy: 0.3362\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.7191 - accuracy: 0.4065 - val_loss: 5.6605 - val_accuracy: 0.2759\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.3331 - accuracy: 0.3370 - val_loss: 4.6526 - val_accuracy: 0.3448\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.7917 - accuracy: 0.3696 - val_loss: 3.7550 - val_accuracy: 0.4138\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.2004 - accuracy: 0.3196 - val_loss: 2.9206 - val_accuracy: 0.3534\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4356 - accuracy: 0.3652 - val_loss: 2.3385 - val_accuracy: 0.4138\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0009 - accuracy: 0.4630 - val_loss: 3.4201 - val_accuracy: 0.3966\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8731 - accuracy: 0.4261 - val_loss: 3.5639 - val_accuracy: 0.3966\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8200 - accuracy: 0.4543 - val_loss: 2.3092 - val_accuracy: 0.4741\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.2258 - accuracy: 0.4457 - val_loss: 1.5306 - val_accuracy: 0.5086\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5619 - accuracy: 0.4804 - val_loss: 2.1316 - val_accuracy: 0.4138\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0424 - accuracy: 0.4261 - val_loss: 1.7886 - val_accuracy: 0.4655\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.4083 - accuracy: 0.5348 - val_loss: 1.7305 - val_accuracy: 0.4655\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4518 - accuracy: 0.5283 - val_loss: 1.7037 - val_accuracy: 0.4483\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5133 - accuracy: 0.5109 - val_loss: 1.3633 - val_accuracy: 0.4828\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.1773 - accuracy: 0.5630 - val_loss: 1.4513 - val_accuracy: 0.4397\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2871 - accuracy: 0.5196 - val_loss: 1.3884 - val_accuracy: 0.4397\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2565 - accuracy: 0.5478 - val_loss: 1.2555 - val_accuracy: 0.4741\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.1072 - accuracy: 0.5696 - val_loss: 1.2905 - val_accuracy: 0.4569\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1321 - accuracy: 0.5609 - val_loss: 1.2425 - val_accuracy: 0.4828\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0588 - accuracy: 0.5500 - val_loss: 1.0887 - val_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0253 - accuracy: 0.5804 - val_loss: 1.1647 - val_accuracy: 0.5345\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9985 - accuracy: 0.5935 - val_loss: 1.0986 - val_accuracy: 0.5603\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9390 - accuracy: 0.6065 - val_loss: 1.1453 - val_accuracy: 0.5431\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9587 - accuracy: 0.5739 - val_loss: 1.0316 - val_accuracy: 0.5517\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8882 - accuracy: 0.6065 - val_loss: 1.0922 - val_accuracy: 0.5690\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8962 - accuracy: 0.6065 - val_loss: 1.0976 - val_accuracy: 0.5517\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8673 - accuracy: 0.6304 - val_loss: 1.0593 - val_accuracy: 0.5603\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8503 - accuracy: 0.6174 - val_loss: 1.0489 - val_accuracy: 0.5862\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8358 - accuracy: 0.6348 - val_loss: 1.0435 - val_accuracy: 0.5431\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8225 - accuracy: 0.6609 - val_loss: 1.0313 - val_accuracy: 0.5603\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8079 - accuracy: 0.6804 - val_loss: 1.0432 - val_accuracy: 0.5862\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8079 - accuracy: 0.6478 - val_loss: 1.0381 - val_accuracy: 0.5603\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7970 - accuracy: 0.6609 - val_loss: 1.0587 - val_accuracy: 0.5776\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7856 - accuracy: 0.6696 - val_loss: 1.0179 - val_accuracy: 0.6121\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7805 - accuracy: 0.6696 - val_loss: 1.0174 - val_accuracy: 0.5776\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7662 - accuracy: 0.6870 - val_loss: 1.0509 - val_accuracy: 0.5517\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7601 - accuracy: 0.6848 - val_loss: 1.0373 - val_accuracy: 0.5603\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7529 - accuracy: 0.6870 - val_loss: 1.0045 - val_accuracy: 0.5862\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7449 - accuracy: 0.6935 - val_loss: 1.0211 - val_accuracy: 0.5690\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7432 - accuracy: 0.7087 - val_loss: 1.0094 - val_accuracy: 0.5862\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7348 - accuracy: 0.7065 - val_loss: 1.0101 - val_accuracy: 0.5862\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7283 - accuracy: 0.7022 - val_loss: 0.9857 - val_accuracy: 0.6034\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7307 - accuracy: 0.7065 - val_loss: 0.9965 - val_accuracy: 0.5948\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7241 - accuracy: 0.7000 - val_loss: 0.9936 - val_accuracy: 0.5776\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7138 - accuracy: 0.7065 - val_loss: 0.9918 - val_accuracy: 0.6207\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7154 - accuracy: 0.7130 - val_loss: 0.9975 - val_accuracy: 0.6121\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7064 - accuracy: 0.7174 - val_loss: 0.9884 - val_accuracy: 0.6207\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7070 - accuracy: 0.7087 - val_loss: 0.9822 - val_accuracy: 0.6034\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.7239 - val_loss: 1.0336 - val_accuracy: 0.6034\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.7261 - val_loss: 0.9857 - val_accuracy: 0.6293\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6915 - accuracy: 0.7261 - val_loss: 0.9668 - val_accuracy: 0.6293\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6882 - accuracy: 0.7304 - val_loss: 0.9764 - val_accuracy: 0.6034\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.7304 - val_loss: 1.0205 - val_accuracy: 0.6034\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6817 - accuracy: 0.7087 - val_loss: 1.0007 - val_accuracy: 0.5948\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6770 - accuracy: 0.7239 - val_loss: 0.9687 - val_accuracy: 0.6121\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6646 - accuracy: 0.7370 - val_loss: 1.0186 - val_accuracy: 0.5862\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6595 - accuracy: 0.7413 - val_loss: 0.9829 - val_accuracy: 0.5948\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.7500 - val_loss: 0.9818 - val_accuracy: 0.5948\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6518 - accuracy: 0.7565 - val_loss: 0.9987 - val_accuracy: 0.6121\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.7587 - val_loss: 0.9875 - val_accuracy: 0.6034\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6485 - accuracy: 0.7478 - val_loss: 0.9955 - val_accuracy: 0.5862\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6418 - accuracy: 0.7522 - val_loss: 0.9765 - val_accuracy: 0.6379\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.7543 - val_loss: 1.0059 - val_accuracy: 0.6034\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6355 - accuracy: 0.7522 - val_loss: 1.0306 - val_accuracy: 0.6121\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6412 - accuracy: 0.7565 - val_loss: 0.9850 - val_accuracy: 0.6034\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6313 - accuracy: 0.7652 - val_loss: 1.0062 - val_accuracy: 0.6121\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6282 - accuracy: 0.7674 - val_loss: 0.9839 - val_accuracy: 0.6121\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6435 - accuracy: 0.7609 - val_loss: 0.9898 - val_accuracy: 0.6207\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6261 - accuracy: 0.7674 - val_loss: 1.0620 - val_accuracy: 0.6121\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.7522 - val_loss: 0.9785 - val_accuracy: 0.6207\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6215 - accuracy: 0.7739 - val_loss: 1.0206 - val_accuracy: 0.6207\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6185 - accuracy: 0.7891 - val_loss: 1.0430 - val_accuracy: 0.6034\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.7630 - val_loss: 1.0020 - val_accuracy: 0.6293\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6139 - accuracy: 0.7696 - val_loss: 0.9984 - val_accuracy: 0.6207\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5986 - accuracy: 0.7848 - val_loss: 1.0096 - val_accuracy: 0.5948\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6003 - accuracy: 0.7630 - val_loss: 1.0458 - val_accuracy: 0.6034\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.7717 - val_loss: 1.0085 - val_accuracy: 0.6293\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.7739 - val_loss: 1.0406 - val_accuracy: 0.5948\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5948 - accuracy: 0.7674 - val_loss: 1.0195 - val_accuracy: 0.5948\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5858 - accuracy: 0.7935 - val_loss: 1.0300 - val_accuracy: 0.6293\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5812 - accuracy: 0.7761 - val_loss: 1.0617 - val_accuracy: 0.6121\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5814 - accuracy: 0.7978 - val_loss: 1.0236 - val_accuracy: 0.6207\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5767 - accuracy: 0.7935 - val_loss: 1.0386 - val_accuracy: 0.6379\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5714 - accuracy: 0.7870 - val_loss: 1.0417 - val_accuracy: 0.6293\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.8000 - val_loss: 1.0557 - val_accuracy: 0.6466\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5658 - accuracy: 0.8000 - val_loss: 1.0507 - val_accuracy: 0.6466\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5694 - accuracy: 0.7913 - val_loss: 1.0585 - val_accuracy: 0.6379\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5728 - accuracy: 0.8022 - val_loss: 1.0661 - val_accuracy: 0.6207\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5637 - accuracy: 0.7783 - val_loss: 1.0510 - val_accuracy: 0.6379\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5555 - accuracy: 0.7978 - val_loss: 1.0760 - val_accuracy: 0.6466\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5622 - accuracy: 0.8043 - val_loss: 1.0385 - val_accuracy: 0.6121\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.7957 - val_loss: 1.0615 - val_accuracy: 0.6379\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5519 - accuracy: 0.8065 - val_loss: 1.0485 - val_accuracy: 0.6207\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.8152 - val_loss: 1.0613 - val_accuracy: 0.6207\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5401 - accuracy: 0.8261 - val_loss: 1.0494 - val_accuracy: 0.6207\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5404 - accuracy: 0.8109 - val_loss: 1.0652 - val_accuracy: 0.6293\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5435 - accuracy: 0.8109 - val_loss: 1.0585 - val_accuracy: 0.6034\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.8196 - val_loss: 1.0505 - val_accuracy: 0.6293\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.8130 - val_loss: 1.0792 - val_accuracy: 0.6207\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.8043 - val_loss: 1.0845 - val_accuracy: 0.6293\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5340 - accuracy: 0.8130 - val_loss: 1.0494 - val_accuracy: 0.6466\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5275 - accuracy: 0.8196 - val_loss: 1.0687 - val_accuracy: 0.6293\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.8174 - val_loss: 1.0998 - val_accuracy: 0.6207\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.8109 - val_loss: 1.0460 - val_accuracy: 0.6552\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.8130 - val_loss: 1.1128 - val_accuracy: 0.6293\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5150 - accuracy: 0.8065 - val_loss: 1.0950 - val_accuracy: 0.6207\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.8196 - val_loss: 1.0547 - val_accuracy: 0.6552\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5201 - accuracy: 0.8217 - val_loss: 1.1020 - val_accuracy: 0.6379\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.7957 - val_loss: 1.0854 - val_accuracy: 0.6207\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.8239 - val_loss: 1.0565 - val_accuracy: 0.6466\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5160 - accuracy: 0.8217 - val_loss: 1.1353 - val_accuracy: 0.6121\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.8196 - val_loss: 1.1247 - val_accuracy: 0.6207\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.8261 - val_loss: 1.0653 - val_accuracy: 0.6293\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5038 - accuracy: 0.8152 - val_loss: 1.1173 - val_accuracy: 0.6379\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4973 - accuracy: 0.8348 - val_loss: 1.1208 - val_accuracy: 0.6207\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.8435 - val_loss: 1.1010 - val_accuracy: 0.6466\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5095 - accuracy: 0.8261 - val_loss: 1.1227 - val_accuracy: 0.6552\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.8348 - val_loss: 1.1347 - val_accuracy: 0.6207\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.85 - 0s 8ms/step - loss: 0.4841 - accuracy: 0.8435 - val_loss: 1.0963 - val_accuracy: 0.6466\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.8435 - val_loss: 1.1122 - val_accuracy: 0.6379\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.8457 - val_loss: 1.1183 - val_accuracy: 0.6207\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.8500 - val_loss: 1.0938 - val_accuracy: 0.6293\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4747 - accuracy: 0.8457 - val_loss: 1.1094 - val_accuracy: 0.6293\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.8391 - val_loss: 1.1379 - val_accuracy: 0.6293\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.8478 - val_loss: 1.1067 - val_accuracy: 0.6466\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.8457 - val_loss: 1.1535 - val_accuracy: 0.6379\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.8348 - val_loss: 1.1434 - val_accuracy: 0.6466\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.8326 - val_loss: 1.1173 - val_accuracy: 0.6379\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4562 - accuracy: 0.8522 - val_loss: 1.1818 - val_accuracy: 0.6379\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.8435 - val_loss: 1.1284 - val_accuracy: 0.6293\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.8413 - val_loss: 1.1279 - val_accuracy: 0.6293\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.8609 - val_loss: 1.1653 - val_accuracy: 0.6466\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.8522 - val_loss: 1.1492 - val_accuracy: 0.6207\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.8587 - val_loss: 1.1483 - val_accuracy: 0.6379\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.8587 - val_loss: 1.1630 - val_accuracy: 0.6379\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.8565 - val_loss: 1.1530 - val_accuracy: 0.6379\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.8587 - val_loss: 1.1438 - val_accuracy: 0.6293\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.8652 - val_loss: 1.2025 - val_accuracy: 0.6379\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.8543 - val_loss: 1.1405 - val_accuracy: 0.6466\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.8543 - val_loss: 1.1940 - val_accuracy: 0.6379\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8674 - val_loss: 1.1670 - val_accuracy: 0.6293\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.8696 - val_loss: 1.1568 - val_accuracy: 0.6379\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.8565 - val_loss: 1.2004 - val_accuracy: 0.6379\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.85 - 0s 8ms/step - loss: 0.4250 - accuracy: 0.8783 - val_loss: 1.1530 - val_accuracy: 0.6552\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.8630 - val_loss: 1.1944 - val_accuracy: 0.6466\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.8565 - val_loss: 1.1781 - val_accuracy: 0.6466\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.8543 - val_loss: 1.1776 - val_accuracy: 0.6466\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4382 - accuracy: 0.8609 - val_loss: 1.2428 - val_accuracy: 0.6207\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.8652 - val_loss: 1.1669 - val_accuracy: 0.6552\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8674 - val_loss: 1.2451 - val_accuracy: 0.6379\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4369 - accuracy: 0.8500 - val_loss: 1.1973 - val_accuracy: 0.6552\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8543 - val_loss: 1.1777 - val_accuracy: 0.6638\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8674 - val_loss: 1.2803 - val_accuracy: 0.6379\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.8630 - val_loss: 1.1772 - val_accuracy: 0.6379\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.8413 - val_loss: 1.2429 - val_accuracy: 0.6379\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.8674 - val_loss: 1.2788 - val_accuracy: 0.6379\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8565 - val_loss: 1.1833 - val_accuracy: 0.6466\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8543 - val_loss: 1.3077 - val_accuracy: 0.6466\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.8587 - val_loss: 1.2571 - val_accuracy: 0.6379\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8609 - val_loss: 1.2077 - val_accuracy: 0.6379\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.8783 - val_loss: 1.3461 - val_accuracy: 0.6207\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8652 - val_loss: 1.2381 - val_accuracy: 0.6552\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8652 - val_loss: 1.2303 - val_accuracy: 0.6552\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8783 - val_loss: 1.2893 - val_accuracy: 0.6724\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8739 - val_loss: 1.2488 - val_accuracy: 0.6552\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8739 - val_loss: 1.2570 - val_accuracy: 0.6379\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8761 - val_loss: 1.2893 - val_accuracy: 0.6379\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8804 - val_loss: 1.2689 - val_accuracy: 0.6552\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3816 - accuracy: 0.8826 - val_loss: 1.2620 - val_accuracy: 0.6552\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8696 - val_loss: 1.3037 - val_accuracy: 0.6552\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8870 - val_loss: 1.2561 - val_accuracy: 0.6810\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3723 - accuracy: 0.8848 - val_loss: 1.3092 - val_accuracy: 0.6293\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3740 - accuracy: 0.8978 - val_loss: 1.2967 - val_accuracy: 0.6552\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3748 - accuracy: 0.8870 - val_loss: 1.2697 - val_accuracy: 0.6638\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8739 - val_loss: 1.2844 - val_accuracy: 0.6466\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3692 - accuracy: 0.9000 - val_loss: 1.3084 - val_accuracy: 0.6810\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3681 - accuracy: 0.8826 - val_loss: 1.2800 - val_accuracy: 0.6724\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8848 - val_loss: 1.3139 - val_accuracy: 0.6379\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3630 - accuracy: 0.9022 - val_loss: 1.3131 - val_accuracy: 0.6638\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8848 - val_loss: 1.2964 - val_accuracy: 0.6466\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8935 - val_loss: 1.3178 - val_accuracy: 0.6810\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.9043 - val_loss: 1.3234 - val_accuracy: 0.6638\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3581 - accuracy: 0.8978 - val_loss: 1.3242 - val_accuracy: 0.6638\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8913 - val_loss: 1.3480 - val_accuracy: 0.6379\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8804 - val_loss: 1.3474 - val_accuracy: 0.6810\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8870 - val_loss: 1.3060 - val_accuracy: 0.6379\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3672 - accuracy: 0.8848 - val_loss: 1.3638 - val_accuracy: 0.6897\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3702 - accuracy: 0.8848 - val_loss: 1.3176 - val_accuracy: 0.6724\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.8913 - val_loss: 1.3955 - val_accuracy: 0.6293\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.8978 - val_loss: 1.3752 - val_accuracy: 0.6724\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.9000 - val_loss: 1.3488 - val_accuracy: 0.6897\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3319 - accuracy: 0.9087 - val_loss: 1.3788 - val_accuracy: 0.6638\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3377 - accuracy: 0.9065 - val_loss: 1.3452 - val_accuracy: 0.6810\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.9000 - val_loss: 1.3638 - val_accuracy: 0.6897\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3242 - accuracy: 0.9000 - val_loss: 1.3610 - val_accuracy: 0.6466\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3308 - accuracy: 0.9022 - val_loss: 1.3517 - val_accuracy: 0.6897\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3186 - accuracy: 0.9109 - val_loss: 1.4016 - val_accuracy: 0.6983\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.9087 - val_loss: 1.3852 - val_accuracy: 0.6638\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3280 - accuracy: 0.9109 - val_loss: 1.3659 - val_accuracy: 0.6466\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3098 - accuracy: 0.9239 - val_loss: 1.4170 - val_accuracy: 0.6983\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3221 - accuracy: 0.9065 - val_loss: 1.3860 - val_accuracy: 0.6810\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.9174 - val_loss: 1.3776 - val_accuracy: 0.6466\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3172 - accuracy: 0.9043 - val_loss: 1.4040 - val_accuracy: 0.7155\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3157 - accuracy: 0.9087 - val_loss: 1.3841 - val_accuracy: 0.6983\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3021 - accuracy: 0.9217 - val_loss: 1.3933 - val_accuracy: 0.6724\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3089 - accuracy: 0.9152 - val_loss: 1.4086 - val_accuracy: 0.6983\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.92 - 0s 8ms/step - loss: 0.2999 - accuracy: 0.9196 - val_loss: 1.4041 - val_accuracy: 0.6810\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2983 - accuracy: 0.9196 - val_loss: 1.3987 - val_accuracy: 0.6810\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2936 - accuracy: 0.9283 - val_loss: 1.4367 - val_accuracy: 0.6897\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.9152 - val_loss: 1.4162 - val_accuracy: 0.6983\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2941 - accuracy: 0.9239 - val_loss: 1.4056 - val_accuracy: 0.6724\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2851 - accuracy: 0.9370 - val_loss: 1.4342 - val_accuracy: 0.7069\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2907 - accuracy: 0.9174 - val_loss: 1.4173 - val_accuracy: 0.6897\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2872 - accuracy: 0.9326 - val_loss: 1.4214 - val_accuracy: 0.6897\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2826 - accuracy: 0.9304 - val_loss: 1.4547 - val_accuracy: 0.7069\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2873 - accuracy: 0.9174 - val_loss: 1.4191 - val_accuracy: 0.6810\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2844 - accuracy: 0.9196 - val_loss: 1.4421 - val_accuracy: 0.7069\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2829 - accuracy: 0.9348 - val_loss: 1.4382 - val_accuracy: 0.6810\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2732 - accuracy: 0.9348 - val_loss: 1.4495 - val_accuracy: 0.6983\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.9217 - val_loss: 1.4697 - val_accuracy: 0.7241\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2890 - accuracy: 0.9152 - val_loss: 1.4311 - val_accuracy: 0.6983\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2767 - accuracy: 0.9283 - val_loss: 1.4445 - val_accuracy: 0.6638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2723 - accuracy: 0.9304 - val_loss: 1.4580 - val_accuracy: 0.7155\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2759 - accuracy: 0.9261 - val_loss: 1.4446 - val_accuracy: 0.6897\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2649 - accuracy: 0.9413 - val_loss: 1.5017 - val_accuracy: 0.6897\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2797 - accuracy: 0.9304 - val_loss: 1.4746 - val_accuracy: 0.6897\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2782 - accuracy: 0.9152 - val_loss: 1.4527 - val_accuracy: 0.7069\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2716 - accuracy: 0.9304 - val_loss: 1.4764 - val_accuracy: 0.6983\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2701 - accuracy: 0.9217 - val_loss: 1.4592 - val_accuracy: 0.6810\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2611 - accuracy: 0.9174 - val_loss: 1.5123 - val_accuracy: 0.7241\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2638 - accuracy: 0.9326 - val_loss: 1.4637 - val_accuracy: 0.6810\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2648 - accuracy: 0.9283 - val_loss: 1.4974 - val_accuracy: 0.7069\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2639 - accuracy: 0.9217 - val_loss: 1.4971 - val_accuracy: 0.6638\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.9261 - val_loss: 1.4712 - val_accuracy: 0.6724\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2469 - accuracy: 0.9478 - val_loss: 1.5555 - val_accuracy: 0.7069\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2666 - accuracy: 0.9283 - val_loss: 1.5056 - val_accuracy: 0.6897\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2490 - accuracy: 0.9326 - val_loss: 1.4921 - val_accuracy: 0.6897\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2459 - accuracy: 0.9435 - val_loss: 1.5165 - val_accuracy: 0.6897\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2444 - accuracy: 0.9413 - val_loss: 1.5181 - val_accuracy: 0.6983\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.9457 - val_loss: 1.5070 - val_accuracy: 0.6810\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2376 - accuracy: 0.9543 - val_loss: 1.5485 - val_accuracy: 0.7241\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2417 - accuracy: 0.9370 - val_loss: 1.5261 - val_accuracy: 0.6897\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.94 - 0s 8ms/step - loss: 0.2299 - accuracy: 0.9435 - val_loss: 1.5153 - val_accuracy: 0.6810\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2345 - accuracy: 0.9478 - val_loss: 1.5601 - val_accuracy: 0.6810\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2396 - accuracy: 0.9413 - val_loss: 1.5254 - val_accuracy: 0.7069\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2317 - accuracy: 0.9457 - val_loss: 1.5140 - val_accuracy: 0.6810\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2274 - accuracy: 0.9435 - val_loss: 1.5714 - val_accuracy: 0.6897\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2334 - accuracy: 0.9522 - val_loss: 1.5432 - val_accuracy: 0.6897\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2296 - accuracy: 0.9543 - val_loss: 1.5310 - val_accuracy: 0.6810\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2242 - accuracy: 0.9522 - val_loss: 1.5935 - val_accuracy: 0.6810\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2329 - accuracy: 0.9478 - val_loss: 1.5558 - val_accuracy: 0.7069\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2227 - accuracy: 0.9522 - val_loss: 1.5476 - val_accuracy: 0.6983\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2284 - accuracy: 0.9457 - val_loss: 1.5715 - val_accuracy: 0.6724\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2166 - accuracy: 0.9500 - val_loss: 1.5614 - val_accuracy: 0.6897\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2148 - accuracy: 0.9543 - val_loss: 1.5878 - val_accuracy: 0.6810\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2187 - accuracy: 0.9457 - val_loss: 1.5701 - val_accuracy: 0.6983\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2090 - accuracy: 0.9652 - val_loss: 1.5644 - val_accuracy: 0.7155\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2180 - accuracy: 0.9543 - val_loss: 1.5789 - val_accuracy: 0.6724\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2073 - accuracy: 0.9587 - val_loss: 1.5779 - val_accuracy: 0.6983\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2093 - accuracy: 0.9457 - val_loss: 1.5886 - val_accuracy: 0.7155\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2069 - accuracy: 0.9543 - val_loss: 1.5872 - val_accuracy: 0.6897\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2007 - accuracy: 0.9522 - val_loss: 1.5881 - val_accuracy: 0.7069\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2012 - accuracy: 0.9543 - val_loss: 1.6000 - val_accuracy: 0.6983\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2071 - accuracy: 0.9543 - val_loss: 1.6026 - val_accuracy: 0.6983\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2042 - accuracy: 0.9500 - val_loss: 1.6012 - val_accuracy: 0.7069\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1986 - accuracy: 0.9630 - val_loss: 1.6285 - val_accuracy: 0.7069\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1967 - accuracy: 0.9609 - val_loss: 1.6053 - val_accuracy: 0.6897\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.9522 - val_loss: 1.6079 - val_accuracy: 0.6897\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2028 - accuracy: 0.9543 - val_loss: 1.6204 - val_accuracy: 0.6983\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2014 - accuracy: 0.9522 - val_loss: 1.6077 - val_accuracy: 0.6897\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1926 - accuracy: 0.9587 - val_loss: 1.6433 - val_accuracy: 0.6897\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1914 - accuracy: 0.9609 - val_loss: 1.6216 - val_accuracy: 0.6724\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1956 - accuracy: 0.9630 - val_loss: 1.6205 - val_accuracy: 0.7241\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1977 - accuracy: 0.9587 - val_loss: 1.6305 - val_accuracy: 0.7155\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1998 - accuracy: 0.9478 - val_loss: 1.6276 - val_accuracy: 0.7069\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9717 - val_loss: 1.6611 - val_accuracy: 0.6983\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1935 - accuracy: 0.9587 - val_loss: 1.6586 - val_accuracy: 0.6983\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1861 - accuracy: 0.9478 - val_loss: 1.6386 - val_accuracy: 0.7241\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1909 - accuracy: 0.9609 - val_loss: 1.6577 - val_accuracy: 0.7069\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.9478 - val_loss: 1.6686 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1768 - accuracy: 0.9630 - val_loss: 1.6590 - val_accuracy: 0.7069\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1864 - accuracy: 0.9630 - val_loss: 1.6720 - val_accuracy: 0.6897\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1808 - accuracy: 0.9587 - val_loss: 1.6617 - val_accuracy: 0.6983\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1760 - accuracy: 0.9674 - val_loss: 1.6560 - val_accuracy: 0.7069\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1802 - accuracy: 0.9652 - val_loss: 1.6695 - val_accuracy: 0.6983\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1755 - accuracy: 0.9609 - val_loss: 1.6657 - val_accuracy: 0.6983\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1683 - accuracy: 0.9717 - val_loss: 1.6740 - val_accuracy: 0.6810\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1737 - accuracy: 0.9652 - val_loss: 1.6845 - val_accuracy: 0.6897\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1710 - accuracy: 0.9674 - val_loss: 1.6871 - val_accuracy: 0.6897\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1654 - accuracy: 0.9674 - val_loss: 1.6960 - val_accuracy: 0.6810\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1701 - accuracy: 0.9696 - val_loss: 1.6934 - val_accuracy: 0.6897\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1697 - accuracy: 0.9652 - val_loss: 1.6911 - val_accuracy: 0.6983\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1692 - accuracy: 0.9630 - val_loss: 1.7029 - val_accuracy: 0.7069\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1624 - accuracy: 0.9696 - val_loss: 1.7194 - val_accuracy: 0.6897\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.9739 - val_loss: 1.6991 - val_accuracy: 0.6983\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1651 - accuracy: 0.9630 - val_loss: 1.6966 - val_accuracy: 0.7241\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1606 - accuracy: 0.9652 - val_loss: 1.7241 - val_accuracy: 0.7155\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9717 - val_loss: 1.7037 - val_accuracy: 0.6810\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1638 - accuracy: 0.9565 - val_loss: 1.6947 - val_accuracy: 0.7155\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1535 - accuracy: 0.9739 - val_loss: 1.7427 - val_accuracy: 0.7069\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1639 - accuracy: 0.9652 - val_loss: 1.7294 - val_accuracy: 0.6983\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1611 - accuracy: 0.9609 - val_loss: 1.7211 - val_accuracy: 0.6983\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.9739 - val_loss: 1.7489 - val_accuracy: 0.7069\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.9739 - val_loss: 1.7219 - val_accuracy: 0.7069\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.9717 - val_loss: 1.7156 - val_accuracy: 0.7069\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1482 - accuracy: 0.9739 - val_loss: 1.7364 - val_accuracy: 0.6983\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1512 - accuracy: 0.9717 - val_loss: 1.7266 - val_accuracy: 0.7155\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9761 - val_loss: 1.7400 - val_accuracy: 0.7069\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.9761 - val_loss: 1.7657 - val_accuracy: 0.6897\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1486 - accuracy: 0.9739 - val_loss: 1.7494 - val_accuracy: 0.7155\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1458 - accuracy: 0.9848 - val_loss: 1.7453 - val_accuracy: 0.7069\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.9783 - val_loss: 1.7607 - val_accuracy: 0.6897\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.9696 - val_loss: 1.7407 - val_accuracy: 0.7241\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.98 - 0s 8ms/step - loss: 0.1466 - accuracy: 0.9696 - val_loss: 1.7580 - val_accuracy: 0.7069\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1422 - accuracy: 0.9761 - val_loss: 1.7877 - val_accuracy: 0.6897\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1457 - accuracy: 0.9804 - val_loss: 1.7749 - val_accuracy: 0.7155\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1402 - accuracy: 0.9826 - val_loss: 1.7794 - val_accuracy: 0.7069\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.9739 - val_loss: 1.7655 - val_accuracy: 0.7069\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1363 - accuracy: 0.9761 - val_loss: 1.7633 - val_accuracy: 0.7155\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1374 - accuracy: 0.9804 - val_loss: 1.7732 - val_accuracy: 0.7155\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.9761 - val_loss: 1.7721 - val_accuracy: 0.7069\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.9783 - val_loss: 1.7827 - val_accuracy: 0.7328\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1347 - accuracy: 0.9804 - val_loss: 1.7866 - val_accuracy: 0.6983\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9783 - val_loss: 1.7797 - val_accuracy: 0.7241\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9783 - val_loss: 1.7866 - val_accuracy: 0.7155\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 0.9804 - val_loss: 1.7937 - val_accuracy: 0.7069\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 0.9826 - val_loss: 1.7949 - val_accuracy: 0.7069\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1303 - accuracy: 0.9870 - val_loss: 1.8012 - val_accuracy: 0.7155\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1299 - accuracy: 0.9870 - val_loss: 1.8084 - val_accuracy: 0.7069\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.9891 - val_loss: 1.7967 - val_accuracy: 0.7069\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1259 - accuracy: 0.9826 - val_loss: 1.8128 - val_accuracy: 0.6983\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1283 - accuracy: 0.9870 - val_loss: 1.8128 - val_accuracy: 0.7155\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1260 - accuracy: 0.9783 - val_loss: 1.8135 - val_accuracy: 0.7155\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1227 - accuracy: 0.9848 - val_loss: 1.8259 - val_accuracy: 0.6983\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1243 - accuracy: 0.9870 - val_loss: 1.8144 - val_accuracy: 0.7155\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1215 - accuracy: 0.9870 - val_loss: 1.8106 - val_accuracy: 0.7155\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1236 - accuracy: 0.9870 - val_loss: 1.8219 - val_accuracy: 0.7155\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1195 - accuracy: 0.9848 - val_loss: 1.8095 - val_accuracy: 0.7155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.9870 - val_loss: 1.8172 - val_accuracy: 0.7069\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1192 - accuracy: 0.9826 - val_loss: 1.8228 - val_accuracy: 0.7069\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1185 - accuracy: 0.9848 - val_loss: 1.8234 - val_accuracy: 0.7241\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1164 - accuracy: 0.9870 - val_loss: 1.8271 - val_accuracy: 0.7241\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1177 - accuracy: 0.9891 - val_loss: 1.8298 - val_accuracy: 0.7155\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1150 - accuracy: 0.9870 - val_loss: 1.8278 - val_accuracy: 0.7069\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1165 - accuracy: 0.9870 - val_loss: 1.8295 - val_accuracy: 0.7155\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1163 - accuracy: 0.9891 - val_loss: 1.8347 - val_accuracy: 0.7069\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1129 - accuracy: 0.9870 - val_loss: 1.8421 - val_accuracy: 0.7155\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1126 - accuracy: 0.9848 - val_loss: 1.8339 - val_accuracy: 0.7241\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9957 - val_loss: 1.8352 - val_accuracy: 0.7155\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1102 - accuracy: 0.9891 - val_loss: 1.8485 - val_accuracy: 0.7155\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1122 - accuracy: 0.9870 - val_loss: 1.8420 - val_accuracy: 0.7155\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1123 - accuracy: 0.9935 - val_loss: 1.8448 - val_accuracy: 0.7069\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.9891 - val_loss: 1.8658 - val_accuracy: 0.7155\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9870 - val_loss: 1.8488 - val_accuracy: 0.7155\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1079 - accuracy: 0.9978 - val_loss: 1.8429 - val_accuracy: 0.7155\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9891 - val_loss: 1.8644 - val_accuracy: 0.7069\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1096 - accuracy: 0.9891 - val_loss: 1.8574 - val_accuracy: 0.7155\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1054 - accuracy: 0.9978 - val_loss: 1.8575 - val_accuracy: 0.7155\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1093 - accuracy: 0.9913 - val_loss: 1.8723 - val_accuracy: 0.7069\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9913 - val_loss: 1.8618 - val_accuracy: 0.7155\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1045 - accuracy: 0.9957 - val_loss: 1.8641 - val_accuracy: 0.7241\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1033 - accuracy: 0.9957 - val_loss: 1.8838 - val_accuracy: 0.7155\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1037 - accuracy: 0.9957 - val_loss: 1.8698 - val_accuracy: 0.7155\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1036 - accuracy: 0.9957 - val_loss: 1.8694 - val_accuracy: 0.7241\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0996 - accuracy: 0.9935 - val_loss: 1.8759 - val_accuracy: 0.7155\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1031 - accuracy: 0.9935 - val_loss: 1.8739 - val_accuracy: 0.7069\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0985 - accuracy: 0.9957 - val_loss: 1.8781 - val_accuracy: 0.7328\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1023 - accuracy: 0.9978 - val_loss: 1.8841 - val_accuracy: 0.7241\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9978 - val_loss: 1.8974 - val_accuracy: 0.6897\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1016 - accuracy: 0.9913 - val_loss: 1.8803 - val_accuracy: 0.7328\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9978 - val_loss: 1.8966 - val_accuracy: 0.6983\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9957 - val_loss: 1.8968 - val_accuracy: 0.7069\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1012 - accuracy: 0.9891 - val_loss: 1.8969 - val_accuracy: 0.7069\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0975 - accuracy: 0.9935 - val_loss: 1.9077 - val_accuracy: 0.6983\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1020 - accuracy: 0.9957 - val_loss: 1.9191 - val_accuracy: 0.7155\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0967 - accuracy: 0.9957 - val_loss: 1.8988 - val_accuracy: 0.7155\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1014 - accuracy: 0.9913 - val_loss: 1.8874 - val_accuracy: 0.7241\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9978 - val_loss: 1.9130 - val_accuracy: 0.7241\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0997 - accuracy: 0.9913 - val_loss: 1.9166 - val_accuracy: 0.7069\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 0.9913 - val_loss: 1.9206 - val_accuracy: 0.7069\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0893 - accuracy: 0.9978 - val_loss: 1.9327 - val_accuracy: 0.7241\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0949 - accuracy: 0.9957 - val_loss: 1.9188 - val_accuracy: 0.7069\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 1.9240 - val_accuracy: 0.6983\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9978 - val_loss: 1.9332 - val_accuracy: 0.7069\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0902 - accuracy: 0.9978 - val_loss: 1.9305 - val_accuracy: 0.7155\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9978 - val_loss: 1.9213 - val_accuracy: 0.7069\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0955 - accuracy: 0.9957 - val_loss: 1.9291 - val_accuracy: 0.7069\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0930 - accuracy: 0.9957 - val_loss: 1.9619 - val_accuracy: 0.6983\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9978 - val_loss: 1.9401 - val_accuracy: 0.7069\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0906 - accuracy: 0.9978 - val_loss: 1.9451 - val_accuracy: 0.6983\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.9935 - val_loss: 1.9545 - val_accuracy: 0.7155\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 0.9978 - val_loss: 1.9229 - val_accuracy: 0.7069\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9978 - val_loss: 1.9392 - val_accuracy: 0.7069\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9978 - val_loss: 1.9784 - val_accuracy: 0.7069\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9935 - val_loss: 1.9514 - val_accuracy: 0.6983\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0847 - accuracy: 0.9978 - val_loss: 1.9465 - val_accuracy: 0.7241\n",
      "Epoch 402/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 1.9697 - val_accuracy: 0.7069\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9957 - val_loss: 1.9554 - val_accuracy: 0.7069\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 1.9546 - val_accuracy: 0.6983\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9978 - val_loss: 1.9860 - val_accuracy: 0.7069\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9957 - val_loss: 1.9912 - val_accuracy: 0.7155\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0801 - accuracy: 0.9935 - val_loss: 1.9575 - val_accuracy: 0.7155\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9978 - val_loss: 1.9744 - val_accuracy: 0.7069\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 1.9998 - val_accuracy: 0.7069\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9957 - val_loss: 1.9623 - val_accuracy: 0.7069\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 1.9741 - val_accuracy: 0.6983\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 1.9940 - val_accuracy: 0.7069\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9978 - val_loss: 1.9934 - val_accuracy: 0.7155\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0771 - accuracy: 0.9978 - val_loss: 1.9847 - val_accuracy: 0.6983\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.9908 - val_accuracy: 0.7069\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 1.9972 - val_accuracy: 0.7069\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 1.9904 - val_accuracy: 0.6983\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 1.9935 - val_accuracy: 0.6983\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 1.9933 - val_accuracy: 0.7155\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 1.9966 - val_accuracy: 0.7069\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 2.0094 - val_accuracy: 0.6983\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 2.0081 - val_accuracy: 0.7069\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 2.0054 - val_accuracy: 0.6983\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 2.0115 - val_accuracy: 0.6983\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 2.0120 - val_accuracy: 0.7069\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 2.0029 - val_accuracy: 0.7069\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 2.0123 - val_accuracy: 0.6983\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 2.0251 - val_accuracy: 0.6983\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 2.0170 - val_accuracy: 0.7069\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 2.0168 - val_accuracy: 0.7069\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 2.0199 - val_accuracy: 0.6983\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 2.0178 - val_accuracy: 0.6983\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.6983\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 2.0319 - val_accuracy: 0.6983\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 2.0402 - val_accuracy: 0.6983\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 2.0328 - val_accuracy: 0.6983\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 2.0274 - val_accuracy: 0.7069\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 2.0329 - val_accuracy: 0.7069\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 2.0393 - val_accuracy: 0.6897\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 2.0373 - val_accuracy: 0.6983\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 2.0468 - val_accuracy: 0.7069\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 2.0482 - val_accuracy: 0.6983\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 2.0408 - val_accuracy: 0.6983\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 2.0536 - val_accuracy: 0.7069\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 2.0501 - val_accuracy: 0.6983\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0683 - accuracy: 0.9978 - val_loss: 2.0504 - val_accuracy: 0.6983\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 2.0699 - val_accuracy: 0.7155\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 2.0559 - val_accuracy: 0.7069\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9957 - val_loss: 2.0629 - val_accuracy: 0.6983\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 2.0569 - val_accuracy: 0.7069\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 2.0694 - val_accuracy: 0.6897\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 2.0737 - val_accuracy: 0.7069\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 2.0561 - val_accuracy: 0.7069\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 2.0743 - val_accuracy: 0.6983\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 2.0924 - val_accuracy: 0.7069\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 2.0702 - val_accuracy: 0.7069\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 2.0706 - val_accuracy: 0.6983\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.7069\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 2.0900 - val_accuracy: 0.6897\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.6983\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 2.0822 - val_accuracy: 0.6983\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 2.0902 - val_accuracy: 0.6983\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 2.0861 - val_accuracy: 0.6983\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 2.0974 - val_accuracy: 0.6897\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.6983\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 2.0921 - val_accuracy: 0.6983\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 2.0863 - val_accuracy: 0.7069\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 2.1008 - val_accuracy: 0.6983\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 2.1053 - val_accuracy: 0.6983\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 2.0933 - val_accuracy: 0.6897\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 2.1098 - val_accuracy: 0.7069\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 2.1234 - val_accuracy: 0.6983\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 2.1120 - val_accuracy: 0.6983\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 2.1043 - val_accuracy: 0.6983\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 2.1121 - val_accuracy: 0.6983\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 2.1167 - val_accuracy: 0.6983\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 2.1138 - val_accuracy: 0.6983\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 2.1249 - val_accuracy: 0.6983\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 2.1284 - val_accuracy: 0.7155\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 2.1233 - val_accuracy: 0.6897\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 2.1173 - val_accuracy: 0.6983\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 2.1243 - val_accuracy: 0.6983\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 2.1213 - val_accuracy: 0.7069\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 2.1280 - val_accuracy: 0.6983\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 2.1334 - val_accuracy: 0.7069\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 2.1392 - val_accuracy: 0.7069\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 2.1324 - val_accuracy: 0.6983\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 2.1255 - val_accuracy: 0.6983\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.7069\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 2.1482 - val_accuracy: 0.7155\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 2.1428 - val_accuracy: 0.7069\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 2.1407 - val_accuracy: 0.6983\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 2.1426 - val_accuracy: 0.6983\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 2.1423 - val_accuracy: 0.7069\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 2.1454 - val_accuracy: 0.6983\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 2.1549 - val_accuracy: 0.6983\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 2.1558 - val_accuracy: 0.6983\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 2.1414 - val_accuracy: 0.7069\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 2.1570 - val_accuracy: 0.6897\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 2.1666 - val_accuracy: 0.6897\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=300, \n",
    "                                activation='relu', \n",
    "                                input_dim=len(x_train[0])))\n",
    "model.add(tf.keras.layers.Dense(units=4, \n",
    "                                activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=500,\n",
    "                    batch_size=256,\n",
    "                    validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
